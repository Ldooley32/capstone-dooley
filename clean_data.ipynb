{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "1. The data retrieved from CDC were in multiple files that are year dependent. The files will need to be combined\n",
    "2. Once the files are combined then all unnecessary attributes will be removed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Table Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files from C:\\Users\\laura\\OneDrive\\Documents\\capstone-dooley\\data\\antibiotic usage\\prescriptions have been combined and saved to combined_prescription_rate.csv.\n",
      "All CSV files from C:\\Users\\laura\\OneDrive\\Documents\\capstone-dooley\\data\\antibiotic usage\\saar have been combined and saved to combined_saar.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laura\\AppData\\Local\\Temp\\ipykernel_7488\\3393467354.py:17: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files from C:\\Users\\laura\\OneDrive\\Documents\\capstone-dooley\\data\\resistance have been combined and saved to combined_resistance.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def combine_csv_files(input_folder, output_file):\n",
    "    # Check if the output file already exists\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"The output file '{output_file}' already exists. No changes were made.\")\n",
    "        return\n",
    "    \n",
    "    # List to hold dataframes\n",
    "    dataframes = []\n",
    "    \n",
    "    # Iterate over all files in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)\n",
    "    \n",
    "    # Concatenate all dataframes\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Save the combined dataframe to the specified output file\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(f\"All CSV files from {input_folder} have been combined and saved to {output_file}.\")\n",
    "\n",
    "# Create Combined file\n",
    "input_folder = r\"C:\\Users\\laura\\OneDrive\\Documents\\capstone-dooley\\data\\antibiotic usage\\prescriptions\"\n",
    "output_file = 'combined_prescription_rate.csv'\n",
    "input_folder2 = r'C:\\Users\\laura\\OneDrive\\Documents\\capstone-dooley\\data\\antibiotic usage\\saar'\n",
    "output_file2 = 'combined_saar.csv'\n",
    "input_folder3 = r'C:\\Users\\laura\\OneDrive\\Documents\\capstone-dooley\\data\\resistance'\n",
    "output_file3 = 'combined_resistance.csv'\n",
    "\n",
    "combine_csv_files(input_folder, output_file)\n",
    "combine_csv_files(input_folder2, output_file2)\n",
    "combine_csv_files(input_folder3, output_file3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary of the new files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 310\n",
      "Number of columns: 6\n",
      "\n",
      "Column Information:\n",
      "ID State                                int64\n",
      "State                                  object\n",
      "Year                                  float64\n",
      "Prescriptions per 1,000 Enrollees     float64\n",
      "Event Year                            float64\n",
      "Prescriptions per 1,000 Population    float64\n",
      "dtype: object\n",
      "\n",
      "Summary Statistics for Numerical Columns:\n",
      "         ID State         Year  Prescriptions per 1,000 Enrollees  \\\n",
      "count  310.000000   102.000000                         102.000000   \n",
      "mean    28.587097  2017.500000                        1422.558824   \n",
      "std     15.940337     0.502469                         218.322478   \n",
      "min      0.000000  2017.000000                         996.000000   \n",
      "25%     16.000000  2017.000000                        1235.500000   \n",
      "50%     29.000000  2017.500000                        1408.000000   \n",
      "75%     41.750000  2018.000000                        1575.000000   \n",
      "max     56.000000  2018.000000                        1896.000000   \n",
      "\n",
      "        Event Year  Prescriptions per 1,000 Population  \n",
      "count   208.000000                          208.000000  \n",
      "mean   2020.500000                          688.461538  \n",
      "std       1.120731                          178.874658  \n",
      "min    2019.000000                          348.000000  \n",
      "25%    2019.750000                          560.250000  \n",
      "50%    2020.500000                          671.500000  \n",
      "75%    2021.250000                          790.250000  \n",
      "max    2022.000000                         1193.000000  \n",
      "Number of rows: 180960\n",
      "Number of columns: 10\n",
      "\n",
      "Column Information:\n",
      "phenotype        object\n",
      "State            object\n",
      "eventtype        object\n",
      "year              int64\n",
      "agecat           object\n",
      "numTested        object\n",
      "numNonSuscep     object\n",
      "pctNonSuscep     object\n",
      "Suppress         object\n",
      "displayTested    object\n",
      "dtype: object\n",
      "\n",
      "Summary Statistics for Numerical Columns:\n",
      "                year\n",
      "count  180960.000000\n",
      "mean     2015.500000\n",
      "std         2.872289\n",
      "min      2011.000000\n",
      "25%      2013.000000\n",
      "50%      2015.500000\n",
      "75%      2018.000000\n",
      "max      2020.000000\n",
      "Number of rows: 409\n",
      "Number of columns: 11\n",
      "\n",
      "Column Information:\n",
      "SAAR Population                                 object\n",
      "Agent                                           object\n",
      "Event Year                                       int64\n",
      "State                                           object\n",
      "ID State                                         int64\n",
      "No. of facilities reporting SAARs                int64\n",
      "No. of facilities eligible to report SAARs       int64\n",
      "Percentage of eligible facilities reporting     object\n",
      "Observed Antimicrobial Days                    float64\n",
      "Predicted Antimicrobial Days                   float64\n",
      "Days Present                                   float64\n",
      "dtype: object\n",
      "\n",
      "Summary Statistics for Numerical Columns:\n",
      "        Event Year    ID State  No. of facilities reporting SAARs  \\\n",
      "count   409.000000  409.000000                         409.000000   \n",
      "mean   2021.872861   29.246944                          20.555012   \n",
      "std       0.781823   16.259843                          27.910265   \n",
      "min    2021.000000    1.000000                           0.000000   \n",
      "25%    2021.000000   16.000000                           4.000000   \n",
      "50%    2022.000000   29.000000                          10.000000   \n",
      "75%    2022.000000   42.000000                          24.000000   \n",
      "max    2023.000000   81.000000                         189.000000   \n",
      "\n",
      "       No. of facilities eligible to report SAARs  \\\n",
      "count                                  409.000000   \n",
      "mean                                    47.442543   \n",
      "std                                     61.815406   \n",
      "min                                      1.000000   \n",
      "25%                                     11.000000   \n",
      "50%                                     24.000000   \n",
      "75%                                     66.000000   \n",
      "max                                    415.000000   \n",
      "\n",
      "       Observed Antimicrobial Days  Predicted Antimicrobial Days  Days Present  \n",
      "count                 2.080000e+02                  2.080000e+02  2.080000e+02  \n",
      "mean                  6.907992e+05                  7.237896e+05  1.167282e+06  \n",
      "std                   9.833982e+05                  9.970288e+05  1.550642e+06  \n",
      "min                   1.009400e+04                  1.002713e+04  3.869500e+04  \n",
      "25%                   5.311575e+04                  5.925870e+04  1.651025e+05  \n",
      "50%                   2.783195e+05                  2.808785e+05  4.874140e+05  \n",
      "75%                   9.316078e+05                  1.026701e+06  1.610302e+06  \n",
      "max                   5.566721e+06                  5.131384e+06  7.997617e+06  \n"
     ]
    }
   ],
   "source": [
    "def summarize_csv(file):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Get the number of rows and columns\n",
    "    num_rows, num_columns = df.shape\n",
    "    \n",
    "    # Get column names and data types\n",
    "    column_info = df.dtypes\n",
    "\n",
    "     \n",
    "    # Get summary statistics for numerical columns\n",
    "    summary_stats = df.describe()\n",
    "    \n",
    "    # Print the summary\n",
    "    print(f\"Number of rows: {num_rows}\")\n",
    "    print(f\"Number of columns: {num_columns}\")\n",
    "    print(\"\\nColumn Information:\")\n",
    "    print(column_info)\n",
    "    print(\"\\nSummary Statistics for Numerical Columns:\")\n",
    "    print(summary_stats)\n",
    "\n",
    "# Example usage\n",
    "file = 'combined_prescription_rate.csv'\n",
    "file2 = 'combined_resistance.csv'\n",
    "file3 = 'combined_saar.csv'\n",
    "\n",
    "summarize_csv(file)\n",
    "\n",
    "summarize_csv(file2)\n",
    "\n",
    "summarize_csv(file3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data adjustments \n",
    "1. saar.csv  - needs to switch data type, remove zeros, and add the SAAR value (observed days/predicted days) in a new column \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAAR column added, converted to int64, and saved to updated_saar\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "\n",
    "df = pd.read_csv(file3)\n",
    "\n",
    "# Ensure there are no zero values in 'Predicted Antimicrobial Days'\n",
    "if (df['Predicted Antimicrobial Days'] == 0).any():\n",
    "    print(\"Warning: Found zero values in 'Predicted Antimicrobial Days'. These will be replaced with NaN.\")\n",
    "    df['Predicted Antimicrobial Days'].replace(0, pd.NA, inplace=True)\n",
    "\n",
    "# Add a new column named 'SAAR' while handling division safely\n",
    "df['SAAR'] = df['Observed Antimicrobial Days'] / df['Predicted Antimicrobial Days']\n",
    "\n",
    "# Convert the 'SAAR' column to int64 (dropping NaN before conversion)\n",
    "df['SAAR'] = df['SAAR'].round(4)\n",
    "\n",
    "output_file = 'updated_saar'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"SAAR column added, converted to int64, and saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. resistance.csv - The agecat contains all/adult/peds. All needs to be removed since it is the combination of adult and peds.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with 'All' in the 'agecat' column removed and saved to updated_resistance.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('combined_resistance.csv')\n",
    "\n",
    "# Remove rows where the 'agecat' column is \"All\"\n",
    "df = df[df['agecat'] != \"All\"]\n",
    "\n",
    "# Save the updated DataFrame to a new file\n",
    "output_file_path = 'updated_resistance.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Rows with 'All' in the 'agecat' column removed and saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the CSV file\n",
    "df = pd.read_csv(\"combined_resistance.csv\")\n",
    "\n",
    "# Convert 'pctNonSuscep' to numeric, coercing non-numeric entries to NaN\n",
    "df['pctNonSuscep'] = pd.to_numeric(df['pctNonSuscep'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'pctNonSuscep'\n",
    "df.dropna(subset=['pctNonSuscep'], inplace=True)\n",
    "\n",
    "#  convert it to int64\n",
    "df['pctNonSuscep'] = df['pctNonSuscep'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved to updated_livestock_sales_file.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dictionary mapping state names to abbreviations\n",
    "state_to_abbreviation = {\n",
    "    \"ALABAMA\": \"AL\", \"ALASKA\": \"AK\", \"ARIZONA\": \"AZ\", \"ARKANSAS\": \"AR\",\n",
    "    \"CALIFORNIA\": \"CA\", \"COLORADO\": \"CO\", \"CONNECTICUT\": \"CT\", \"DELAWARE\": \"DE\",\n",
    "    \"FLORIDA\": \"FL\", \"GEORGIA\": \"GA\", \"HAWAII\": \"HI\", \"IDAHO\": \"ID\",\n",
    "    \"ILLINOIS\": \"IL\", \"INDIANA\": \"IN\", \"IOWA\": \"IA\", \"KANSAS\": \"KS\",\n",
    "    \"KENTUCKY\": \"KY\", \"LOUISIANA\": \"LA\", \"MAINE\": \"ME\", \"MARYLAND\": \"MD\",\n",
    "    \"MASSACHUSETTS\": \"MA\", \"MICHIGAN\": \"MI\", \"MINNESOTA\": \"MN\", \"MISSISSIPPI\": \"MS\",\n",
    "    \"MISSOURI\": \"MO\", \"MONTANA\": \"MT\", \"NEBRASKA\": \"NE\", \"NEVADA\": \"NV\",\n",
    "    \"NEW HAMPSHIRE\": \"NH\", \"NEW JERSEY\": \"NJ\", \"NEW MEXICO\": \"NM\", \"NEW YORK\": \"NY\",\n",
    "    \"NORTH CAROLINA\": \"NC\", \"NORTH DAKOTA\": \"ND\", \"OHIO\": \"OH\", \"OKLAHOMA\": \"OK\",\n",
    "    \"OREGON\": \"OR\", \"PENNSYLVANIA\": \"PA\", \"RHODE ISLAND\": \"RI\", \"SOUTH CAROLINA\": \"SC\",\n",
    "    \"SOUTH DAKOTA\": \"SD\", \"TENNESSEE\": \"TN\", \"TEXAS\": \"TX\", \"UTAH\": \"UT\",\n",
    "    \"VERMONT\": \"VT\", \"VIRGINIA\": \"VA\", \"WASHINGTON\": \"WA\", \"WEST VIRGINIA\": \"WV\",\n",
    "    \"WISCONSIN\": \"WI\", \"WYOMING\": \"WY\"\n",
    "}\n",
    "\n",
    "# Load your dataset\n",
    "file_path = r'C:\\Users\\laura\\OneDrive\\Documents\\capstone-dooley\\data\\livestock_sales.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to convert state names to abbreviations\n",
    "def convert_to_abbreviation(state):\n",
    "    return state_to_abbreviation.get(state.upper(), state)  # Default to state if no match found\n",
    "\n",
    "# Apply the function to the State column\n",
    "df['state'] = df['state'].apply(convert_to_abbreviation)\n",
    "\n",
    "# Clean up the \"Value\" column to remove commas and convert to numeric\n",
    "df['Value'] = df['Value'].str.replace(',', '', regex=True)  # Remove commas\n",
    "df['Value'] = pd.to_numeric(df['Value'], errors='coerce')  # Convert to numeric\n",
    "\n",
    "# Drop rows with NaN values in 'Value'\n",
    "df.dropna(subset=['Value'], inplace=True)\n",
    "\n",
    "# Save the updated dataset\n",
    "output_path = 'updated_livestock_sales_file.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Updated file saved to {output_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "switched states to abbrevation on combined_saar.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SAAR Population Agent  Event Year state  ID State  \\\n",
      "0           Adult   All        2021    AL         1   \n",
      "1           Adult   All        2021    AK         2   \n",
      "2           Adult   All        2021    AZ         4   \n",
      "3           Adult   All        2021    AR         5   \n",
      "4           Adult   All        2021    CA         6   \n",
      "\n",
      "   No. of facilities reporting SAARs  \\\n",
      "0                                 20   \n",
      "1                                  5   \n",
      "2                                 11   \n",
      "3                                 24   \n",
      "4                                109   \n",
      "\n",
      "   No. of facilities eligible to report SAARs  \\\n",
      "0                                          91   \n",
      "1                                          16   \n",
      "2                                          78   \n",
      "3                                          66   \n",
      "4                                         362   \n",
      "\n",
      "  Percentage of eligible facilities reporting  Observed Antimicrobial Days  \\\n",
      "0                                      21.90%                     450718.0   \n",
      "1                                      31.20%                          NaN   \n",
      "2                                      14.10%                          NaN   \n",
      "3                                      36.30%                     482607.0   \n",
      "4                                      30.10%                    3390647.0   \n",
      "\n",
      "   Predicted Antimicrobial Days  Days Present  \n",
      "0                      496764.1      743205.0  \n",
      "1                           NaN           NaN  \n",
      "2                           NaN           NaN  \n",
      "3                      481097.7      727446.0  \n",
      "4                     3307234.5     5160141.0  \n"
     ]
    }
   ],
   "source": [
    "# Dictionary mapping state names to abbreviations\n",
    "state_to_abbreviation = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\", \"Colorado\": \"CO\", \"Connecticut\": \"CT\", \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Hawaii\": \"HI\", \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\", \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\", \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\", \"New Mexico\": \"NM\", \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\", \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\", \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\", \"Virginia\": \"VA\", \"Washington\": \"WA\", \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\"\n",
    "}\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"combined_saar.csv\")\n",
    "\n",
    "# Function to convert state names to abbreviations\n",
    "def convert_to_abbreviation(state):\n",
    "    return state_to_abbreviation.get(state, state)  # Default to state if no match found\n",
    "\n",
    "# Apply the function to the state column\n",
    "df['state'] = df['state'].apply(convert_to_abbreviation)\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv(\"updated_saar_file.csv\", index=False)\n",
    "\n",
    "# Check the first few rows to verify\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>avg_SAAR_x</th>\n",
       "      <th>avg_SAAR_y</th>\n",
       "      <th>avg_pctNonSuscep_x</th>\n",
       "      <th>avg_Value_x</th>\n",
       "      <th>avg_SAAR</th>\n",
       "      <th>avg_pctNonSuscep_y</th>\n",
       "      <th>avg_Value_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.439368</td>\n",
       "      <td>3.209917e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329569</td>\n",
       "      <td>3.209917e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>0.353875</td>\n",
       "      <td>0.353875</td>\n",
       "      <td>7.421897</td>\n",
       "      <td>4.211669e+09</td>\n",
       "      <td>0.353875</td>\n",
       "      <td>5.606552</td>\n",
       "      <td>4.211669e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR</td>\n",
       "      <td>0.378725</td>\n",
       "      <td>0.378725</td>\n",
       "      <td>5.125718</td>\n",
       "      <td>5.141045e+09</td>\n",
       "      <td>0.378725</td>\n",
       "      <td>3.747500</td>\n",
       "      <td>5.141045e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZ</td>\n",
       "      <td>0.254575</td>\n",
       "      <td>0.254575</td>\n",
       "      <td>6.923161</td>\n",
       "      <td>1.399922e+09</td>\n",
       "      <td>0.254575</td>\n",
       "      <td>5.201681</td>\n",
       "      <td>1.399922e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>0.982988</td>\n",
       "      <td>0.982988</td>\n",
       "      <td>14.065431</td>\n",
       "      <td>1.062359e+10</td>\n",
       "      <td>0.982988</td>\n",
       "      <td>11.721681</td>\n",
       "      <td>1.062359e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CO</td>\n",
       "      <td>0.483175</td>\n",
       "      <td>0.483175</td>\n",
       "      <td>4.649109</td>\n",
       "      <td>4.598994e+09</td>\n",
       "      <td>0.483175</td>\n",
       "      <td>3.507069</td>\n",
       "      <td>4.598994e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT</td>\n",
       "      <td>0.331825</td>\n",
       "      <td>0.331825</td>\n",
       "      <td>4.389023</td>\n",
       "      <td>1.617532e+08</td>\n",
       "      <td>0.331825</td>\n",
       "      <td>3.231034</td>\n",
       "      <td>1.617532e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.619454</td>\n",
       "      <td>9.236823e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.164397</td>\n",
       "      <td>9.236823e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FL</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>12.014282</td>\n",
       "      <td>1.587410e+09</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>9.443793</td>\n",
       "      <td>1.587410e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GA</td>\n",
       "      <td>0.921362</td>\n",
       "      <td>0.921362</td>\n",
       "      <td>9.830661</td>\n",
       "      <td>5.381134e+09</td>\n",
       "      <td>0.921362</td>\n",
       "      <td>7.558233</td>\n",
       "      <td>5.381134e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HI</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.761466</td>\n",
       "      <td>1.159652e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570086</td>\n",
       "      <td>1.159652e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IA</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>2.269885</td>\n",
       "      <td>1.183444e+10</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>1.652629</td>\n",
       "      <td>1.183444e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ID</td>\n",
       "      <td>0.202613</td>\n",
       "      <td>0.202613</td>\n",
       "      <td>1.079109</td>\n",
       "      <td>3.649840e+09</td>\n",
       "      <td>0.202613</td>\n",
       "      <td>0.812026</td>\n",
       "      <td>3.649840e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IL</td>\n",
       "      <td>0.808775</td>\n",
       "      <td>0.808775</td>\n",
       "      <td>10.315690</td>\n",
       "      <td>2.770862e+09</td>\n",
       "      <td>0.808775</td>\n",
       "      <td>7.875431</td>\n",
       "      <td>2.770862e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IN</td>\n",
       "      <td>0.851263</td>\n",
       "      <td>0.851263</td>\n",
       "      <td>7.030862</td>\n",
       "      <td>3.445690e+09</td>\n",
       "      <td>0.851263</td>\n",
       "      <td>5.348836</td>\n",
       "      <td>3.445690e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KS</td>\n",
       "      <td>0.343100</td>\n",
       "      <td>0.343100</td>\n",
       "      <td>3.631006</td>\n",
       "      <td>1.019706e+10</td>\n",
       "      <td>0.343100</td>\n",
       "      <td>2.714741</td>\n",
       "      <td>1.019706e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KY</td>\n",
       "      <td>0.606800</td>\n",
       "      <td>0.606800</td>\n",
       "      <td>7.463534</td>\n",
       "      <td>2.855916e+09</td>\n",
       "      <td>0.606800</td>\n",
       "      <td>5.572759</td>\n",
       "      <td>2.855916e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LA</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>7.439167</td>\n",
       "      <td>1.004438e+09</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>5.481207</td>\n",
       "      <td>1.004438e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MA</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>8.178678</td>\n",
       "      <td>1.168168e+08</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>6.156034</td>\n",
       "      <td>1.168168e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MD</td>\n",
       "      <td>0.239337</td>\n",
       "      <td>0.239337</td>\n",
       "      <td>5.442055</td>\n",
       "      <td>1.281290e+09</td>\n",
       "      <td>0.239337</td>\n",
       "      <td>3.947651</td>\n",
       "      <td>1.281290e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ME</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>1.444971</td>\n",
       "      <td>2.680240e+08</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>1.082155</td>\n",
       "      <td>2.680240e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MI</td>\n",
       "      <td>0.535775</td>\n",
       "      <td>0.535775</td>\n",
       "      <td>9.196724</td>\n",
       "      <td>2.854516e+09</td>\n",
       "      <td>0.535775</td>\n",
       "      <td>6.969741</td>\n",
       "      <td>2.854516e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MN</td>\n",
       "      <td>0.637512</td>\n",
       "      <td>0.637512</td>\n",
       "      <td>4.797701</td>\n",
       "      <td>6.863294e+09</td>\n",
       "      <td>0.637512</td>\n",
       "      <td>3.542500</td>\n",
       "      <td>6.863294e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MO</td>\n",
       "      <td>0.824512</td>\n",
       "      <td>0.824512</td>\n",
       "      <td>6.838563</td>\n",
       "      <td>4.428056e+09</td>\n",
       "      <td>0.824512</td>\n",
       "      <td>5.214310</td>\n",
       "      <td>4.428056e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MS</td>\n",
       "      <td>0.397175</td>\n",
       "      <td>0.397175</td>\n",
       "      <td>6.846810</td>\n",
       "      <td>3.290200e+09</td>\n",
       "      <td>0.397175</td>\n",
       "      <td>4.949310</td>\n",
       "      <td>3.290200e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MT</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.755747</td>\n",
       "      <td>1.603035e+09</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.570517</td>\n",
       "      <td>1.603035e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NC</td>\n",
       "      <td>0.897763</td>\n",
       "      <td>0.897763</td>\n",
       "      <td>8.163851</td>\n",
       "      <td>8.220149e+09</td>\n",
       "      <td>0.897763</td>\n",
       "      <td>6.243448</td>\n",
       "      <td>8.220149e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ND</td>\n",
       "      <td>0.118538</td>\n",
       "      <td>0.118538</td>\n",
       "      <td>0.468908</td>\n",
       "      <td>1.148980e+09</td>\n",
       "      <td>0.118538</td>\n",
       "      <td>0.344655</td>\n",
       "      <td>1.148980e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NE</td>\n",
       "      <td>0.318725</td>\n",
       "      <td>0.318725</td>\n",
       "      <td>2.906034</td>\n",
       "      <td>1.013382e+10</td>\n",
       "      <td>0.318725</td>\n",
       "      <td>2.113362</td>\n",
       "      <td>1.013382e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NH</td>\n",
       "      <td>0.105063</td>\n",
       "      <td>0.105063</td>\n",
       "      <td>1.005057</td>\n",
       "      <td>8.451300e+07</td>\n",
       "      <td>0.105063</td>\n",
       "      <td>0.746897</td>\n",
       "      <td>8.451300e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NJ</td>\n",
       "      <td>0.887400</td>\n",
       "      <td>0.887400</td>\n",
       "      <td>10.742385</td>\n",
       "      <td>1.164188e+08</td>\n",
       "      <td>0.887400</td>\n",
       "      <td>8.064397</td>\n",
       "      <td>1.164188e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NM</td>\n",
       "      <td>0.359650</td>\n",
       "      <td>0.359650</td>\n",
       "      <td>1.921149</td>\n",
       "      <td>1.668422e+09</td>\n",
       "      <td>0.359650</td>\n",
       "      <td>1.420603</td>\n",
       "      <td>1.668422e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NV</td>\n",
       "      <td>0.509737</td>\n",
       "      <td>0.509737</td>\n",
       "      <td>9.023563</td>\n",
       "      <td>3.492093e+08</td>\n",
       "      <td>0.509737</td>\n",
       "      <td>6.802974</td>\n",
       "      <td>3.492093e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NY</td>\n",
       "      <td>0.928450</td>\n",
       "      <td>0.928450</td>\n",
       "      <td>12.730575</td>\n",
       "      <td>3.004938e+09</td>\n",
       "      <td>0.928450</td>\n",
       "      <td>10.046724</td>\n",
       "      <td>3.004938e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>OH</td>\n",
       "      <td>0.883162</td>\n",
       "      <td>0.883162</td>\n",
       "      <td>10.239425</td>\n",
       "      <td>3.471304e+09</td>\n",
       "      <td>0.883162</td>\n",
       "      <td>8.042198</td>\n",
       "      <td>3.471304e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>OK</td>\n",
       "      <td>0.721525</td>\n",
       "      <td>0.721525</td>\n",
       "      <td>4.771236</td>\n",
       "      <td>4.952164e+09</td>\n",
       "      <td>0.721525</td>\n",
       "      <td>3.577371</td>\n",
       "      <td>4.952164e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OR</td>\n",
       "      <td>0.310762</td>\n",
       "      <td>0.310762</td>\n",
       "      <td>2.522471</td>\n",
       "      <td>1.457854e+09</td>\n",
       "      <td>0.310762</td>\n",
       "      <td>1.892759</td>\n",
       "      <td>1.457854e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PA</td>\n",
       "      <td>0.515475</td>\n",
       "      <td>0.515475</td>\n",
       "      <td>10.459282</td>\n",
       "      <td>4.342366e+09</td>\n",
       "      <td>0.515475</td>\n",
       "      <td>8.453405</td>\n",
       "      <td>4.342366e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>RI</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.518333</td>\n",
       "      <td>1.279217e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.127112</td>\n",
       "      <td>1.279217e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SC</td>\n",
       "      <td>0.544837</td>\n",
       "      <td>0.544837</td>\n",
       "      <td>5.651983</td>\n",
       "      <td>1.630054e+09</td>\n",
       "      <td>0.544837</td>\n",
       "      <td>4.247284</td>\n",
       "      <td>1.630054e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SD</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838506</td>\n",
       "      <td>3.545929e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619828</td>\n",
       "      <td>3.545929e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TN</td>\n",
       "      <td>0.630275</td>\n",
       "      <td>0.630275</td>\n",
       "      <td>9.761149</td>\n",
       "      <td>1.497413e+09</td>\n",
       "      <td>0.630275</td>\n",
       "      <td>7.547672</td>\n",
       "      <td>1.497413e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TX</td>\n",
       "      <td>1.001912</td>\n",
       "      <td>1.001912</td>\n",
       "      <td>12.956494</td>\n",
       "      <td>1.588951e+10</td>\n",
       "      <td>1.001912</td>\n",
       "      <td>10.540647</td>\n",
       "      <td>1.588951e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>UT</td>\n",
       "      <td>0.585662</td>\n",
       "      <td>0.585662</td>\n",
       "      <td>1.992759</td>\n",
       "      <td>1.113018e+09</td>\n",
       "      <td>0.585662</td>\n",
       "      <td>1.497069</td>\n",
       "      <td>1.113018e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>VA</td>\n",
       "      <td>0.982750</td>\n",
       "      <td>0.982750</td>\n",
       "      <td>6.640431</td>\n",
       "      <td>2.315557e+09</td>\n",
       "      <td>0.982750</td>\n",
       "      <td>4.982112</td>\n",
       "      <td>2.315557e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>VT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345862</td>\n",
       "      <td>5.483172e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260948</td>\n",
       "      <td>5.483172e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>WA</td>\n",
       "      <td>0.595513</td>\n",
       "      <td>0.595513</td>\n",
       "      <td>4.790747</td>\n",
       "      <td>2.367232e+09</td>\n",
       "      <td>0.595513</td>\n",
       "      <td>3.546250</td>\n",
       "      <td>2.367232e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>WI</td>\n",
       "      <td>0.526943</td>\n",
       "      <td>0.526943</td>\n",
       "      <td>4.914195</td>\n",
       "      <td>6.507501e+09</td>\n",
       "      <td>0.526943</td>\n",
       "      <td>3.658793</td>\n",
       "      <td>6.507501e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>WV</td>\n",
       "      <td>0.468650</td>\n",
       "      <td>0.468650</td>\n",
       "      <td>4.480632</td>\n",
       "      <td>5.502100e+08</td>\n",
       "      <td>0.468650</td>\n",
       "      <td>3.364569</td>\n",
       "      <td>5.502100e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>WY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.006653e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.006653e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>PR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.311839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.712500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  avg_SAAR_x  avg_SAAR_y  avg_pctNonSuscep_x   avg_Value_x  avg_SAAR  \\\n",
       "0     AK    0.000000    0.000000            0.439368  3.209917e+07  0.000000   \n",
       "1     AL    0.353875    0.353875            7.421897  4.211669e+09  0.353875   \n",
       "2     AR    0.378725    0.378725            5.125718  5.141045e+09  0.378725   \n",
       "3     AZ    0.254575    0.254575            6.923161  1.399922e+09  0.254575   \n",
       "4     CA    0.982988    0.982988           14.065431  1.062359e+10  0.982988   \n",
       "5     CO    0.483175    0.483175            4.649109  4.598994e+09  0.483175   \n",
       "6     CT    0.331825    0.331825            4.389023  1.617532e+08  0.331825   \n",
       "7     DE    0.000000    0.000000            1.619454  9.236823e+08  0.000000   \n",
       "8     FL    0.994413    0.994413           12.014282  1.587410e+09  0.994413   \n",
       "9     GA    0.921362    0.921362            9.830661  5.381134e+09  0.921362   \n",
       "10    HI    0.000000    0.000000            0.761466  1.159652e+08  0.000000   \n",
       "11    IA    0.335900    0.335900            2.269885  1.183444e+10  0.335900   \n",
       "12    ID    0.202613    0.202613            1.079109  3.649840e+09  0.202613   \n",
       "13    IL    0.808775    0.808775           10.315690  2.770862e+09  0.808775   \n",
       "14    IN    0.851263    0.851263            7.030862  3.445690e+09  0.851263   \n",
       "15    KS    0.343100    0.343100            3.631006  1.019706e+10  0.343100   \n",
       "16    KY    0.606800    0.606800            7.463534  2.855916e+09  0.606800   \n",
       "17    LA    0.727600    0.727600            7.439167  1.004438e+09  0.727600   \n",
       "18    MA    0.427400    0.427400            8.178678  1.168168e+08  0.427400   \n",
       "19    MD    0.239337    0.239337            5.442055  1.281290e+09  0.239337   \n",
       "20    ME    0.337900    0.337900            1.444971  2.680240e+08  0.337900   \n",
       "21    MI    0.535775    0.535775            9.196724  2.854516e+09  0.535775   \n",
       "22    MN    0.637512    0.637512            4.797701  6.863294e+09  0.637512   \n",
       "23    MO    0.824512    0.824512            6.838563  4.428056e+09  0.824512   \n",
       "24    MS    0.397175    0.397175            6.846810  3.290200e+09  0.397175   \n",
       "25    MT    0.310000    0.310000            0.755747  1.603035e+09  0.310000   \n",
       "26    NC    0.897763    0.897763            8.163851  8.220149e+09  0.897763   \n",
       "27    ND    0.118538    0.118538            0.468908  1.148980e+09  0.118538   \n",
       "28    NE    0.318725    0.318725            2.906034  1.013382e+10  0.318725   \n",
       "29    NH    0.105063    0.105063            1.005057  8.451300e+07  0.105063   \n",
       "30    NJ    0.887400    0.887400           10.742385  1.164188e+08  0.887400   \n",
       "31    NM    0.359650    0.359650            1.921149  1.668422e+09  0.359650   \n",
       "32    NV    0.509737    0.509737            9.023563  3.492093e+08  0.509737   \n",
       "33    NY    0.928450    0.928450           12.730575  3.004938e+09  0.928450   \n",
       "34    OH    0.883162    0.883162           10.239425  3.471304e+09  0.883162   \n",
       "35    OK    0.721525    0.721525            4.771236  4.952164e+09  0.721525   \n",
       "36    OR    0.310762    0.310762            2.522471  1.457854e+09  0.310762   \n",
       "37    PA    0.515475    0.515475           10.459282  4.342366e+09  0.515475   \n",
       "38    RI    0.000000    0.000000            1.518333  1.279217e+07  0.000000   \n",
       "39    SC    0.544837    0.544837            5.651983  1.630054e+09  0.544837   \n",
       "40    SD    0.000000    0.000000            0.838506  3.545929e+09  0.000000   \n",
       "41    TN    0.630275    0.630275            9.761149  1.497413e+09  0.630275   \n",
       "42    TX    1.001912    1.001912           12.956494  1.588951e+10  1.001912   \n",
       "43    UT    0.585662    0.585662            1.992759  1.113018e+09  0.585662   \n",
       "44    VA    0.982750    0.982750            6.640431  2.315557e+09  0.982750   \n",
       "45    VT    0.000000    0.000000            0.345862  5.483172e+08  0.000000   \n",
       "46    WA    0.595513    0.595513            4.790747  2.367232e+09  0.595513   \n",
       "47    WI    0.526943    0.526943            4.914195  6.507501e+09  0.526943   \n",
       "48    WV    0.468650    0.468650            4.480632  5.502100e+08  0.468650   \n",
       "49    WY    0.000000    0.000000            0.000000  1.006653e+09  0.000000   \n",
       "50    PR         NaN         NaN            6.311839           NaN       NaN   \n",
       "\n",
       "    avg_pctNonSuscep_y   avg_Value_y  \n",
       "0             0.329569  3.209917e+07  \n",
       "1             5.606552  4.211669e+09  \n",
       "2             3.747500  5.141045e+09  \n",
       "3             5.201681  1.399922e+09  \n",
       "4            11.721681  1.062359e+10  \n",
       "5             3.507069  4.598994e+09  \n",
       "6             3.231034  1.617532e+08  \n",
       "7             1.164397  9.236823e+08  \n",
       "8             9.443793  1.587410e+09  \n",
       "9             7.558233  5.381134e+09  \n",
       "10            0.570086  1.159652e+08  \n",
       "11            1.652629  1.183444e+10  \n",
       "12            0.812026  3.649840e+09  \n",
       "13            7.875431  2.770862e+09  \n",
       "14            5.348836  3.445690e+09  \n",
       "15            2.714741  1.019706e+10  \n",
       "16            5.572759  2.855916e+09  \n",
       "17            5.481207  1.004438e+09  \n",
       "18            6.156034  1.168168e+08  \n",
       "19            3.947651  1.281290e+09  \n",
       "20            1.082155  2.680240e+08  \n",
       "21            6.969741  2.854516e+09  \n",
       "22            3.542500  6.863294e+09  \n",
       "23            5.214310  4.428056e+09  \n",
       "24            4.949310  3.290200e+09  \n",
       "25            0.570517  1.603035e+09  \n",
       "26            6.243448  8.220149e+09  \n",
       "27            0.344655  1.148980e+09  \n",
       "28            2.113362  1.013382e+10  \n",
       "29            0.746897  8.451300e+07  \n",
       "30            8.064397  1.164188e+08  \n",
       "31            1.420603  1.668422e+09  \n",
       "32            6.802974  3.492093e+08  \n",
       "33           10.046724  3.004938e+09  \n",
       "34            8.042198  3.471304e+09  \n",
       "35            3.577371  4.952164e+09  \n",
       "36            1.892759  1.457854e+09  \n",
       "37            8.453405  4.342366e+09  \n",
       "38            1.127112  1.279217e+07  \n",
       "39            4.247284  1.630054e+09  \n",
       "40            0.619828  3.545929e+09  \n",
       "41            7.547672  1.497413e+09  \n",
       "42           10.540647  1.588951e+10  \n",
       "43            1.497069  1.113018e+09  \n",
       "44            4.982112  2.315557e+09  \n",
       "45            0.260948  5.483172e+08  \n",
       "46            3.546250  2.367232e+09  \n",
       "47            3.658793  6.507501e+09  \n",
       "48            3.364569  5.502100e+08  \n",
       "49            0.000000  1.006653e+09  \n",
       "50            4.712500           NaN  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_average_per_state(file_name, column_name, state_column):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    # Ensure the specified column is numeric\n",
    "    df[column_name] = pd.to_numeric(df[column_name], errors='coerce')\n",
    "    \n",
    "    # Handle NaN values by filling them with 0\n",
    "    df[column_name] = df[column_name].fillna(0)\n",
    "    \n",
    "    # Calculate the average of the specified column per state\n",
    "    average_per_state = df.groupby(state_column)[column_name].mean().reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    average_per_state.columns = [state_column, f'avg_{column_name}']\n",
    "    \n",
    "    # Check if avg_state.csv exists\n",
    "    try:\n",
    "        existing_df = pd.read_csv(\"avg_state.csv\")\n",
    "        # Ensure the state column names match\n",
    "        if state_column != existing_df.columns[0]:\n",
    "            existing_df.rename(columns={existing_df.columns[0]: state_column}, inplace=True)\n",
    "        # Merge the new average data with the existing data\n",
    "        result_df = pd.merge(existing_df, average_per_state, on=state_column, how='outer')\n",
    "    except FileNotFoundError:\n",
    "        # If the file does not exist, use the new average data as the result\n",
    "        result_df = average_per_state\n",
    "    \n",
    "    # Save the result to avg_state.csv\n",
    "    result_df.to_csv(\"avg_state.csv\", index=False)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Example usage\n",
    "file_name = \"updated_saar_file.csv\"\n",
    "column_name = \"SAAR\"\n",
    "state_column = \"state\"\n",
    "file_name2 = \"updated_resistance.csv\"\n",
    "column_name2 = \"pctNonSuscep\"\n",
    "file_name3 = \"updated_livestock_sales_file.csv\"\n",
    "column_name3 = \"Value\"\n",
    "\n",
    "\n",
    "# Calculate averages and save to avg_state.csv\n",
    "calculate_average_per_state(file_name, column_name, state_column)\n",
    "calculate_average_per_state(file_name2, column_name2, state_column)\n",
    "calculate_average_per_state(file_name3, column_name3, state_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding latitude and longitude to the average_saar_per_state.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   state  avg_saar   latitude   longitude\n",
      "0     AK       NaN  61.370716 -152.404419\n",
      "1     AL  0.943667  32.806671  -86.791130\n",
      "2     AR  1.009933  34.969704  -92.373123\n",
      "3     AZ  1.018300  33.729759 -111.431221\n",
      "4     CA  0.982988  36.116203 -119.681564\n",
      "5     CO  0.773080  39.059811 -105.311104\n",
      "6     CT  0.884867  41.597782  -72.755371\n",
      "7     DE       NaN  38.989590  -75.505987\n",
      "8     FL  0.994413  27.766279  -81.686783\n",
      "9     GA  0.921362  33.040619  -83.643074\n",
      "10    HI       NaN  21.094318 -157.498337\n",
      "11    IA  0.895733  42.011539  -93.210526\n",
      "12    ID  0.810450  44.240459 -114.478828\n",
      "13    IL  0.924314  40.349457  -88.986137\n",
      "14    IN  0.851263  39.849426  -86.258278\n",
      "15    KS  0.914933  38.526600  -96.726486\n",
      "16    KY  0.970880  37.668140  -84.670067\n",
      "17    LA  1.164160  31.169546  -91.867805\n",
      "18    MA  0.854800  42.230171  -71.530106\n",
      "19    MD  0.957350  39.063946  -76.802101\n",
      "20    ME  0.901067  44.693947  -69.381927\n",
      "21    MI  0.857240  43.326618  -84.536095\n",
      "22    MN  1.020020  45.694454  -93.900192\n",
      "23    MO  0.942300  38.456085  -92.288368\n",
      "24    MS  1.059133  32.741646  -89.678696\n",
      "25    MT  0.826667  46.921925 -110.454353\n",
      "26    NC  0.897763  35.630066  -79.806419\n",
      "27    ND  0.948300  47.528912  -99.784012\n",
      "28    NE  0.849933  41.125370  -98.268082\n",
      "29    NH  0.840500  43.452492  -71.563896\n",
      "30    NJ  0.887400  40.298904  -74.521011\n",
      "31    NM  0.959067  34.840515 -106.248482\n",
      "32    NV  1.019475  38.313515 -117.055374\n",
      "33    NY  0.928450  42.165726  -74.948051\n",
      "34    OH  0.883162  40.388783  -82.764915\n",
      "35    OK  1.154440  35.565342  -96.928917\n",
      "36    OR  0.828700  44.572021 -122.070938\n",
      "37    PA  0.824760  40.590752  -77.209755\n",
      "38    PR       NaN        NaN         NaN\n",
      "39    RI       NaN  41.680893  -71.511780\n",
      "40    SC  0.871740  33.856892  -80.945007\n",
      "41    SD       NaN  44.299782  -99.438828\n",
      "42    TN  1.008440  35.747845  -86.692345\n",
      "43    TX  1.001912  31.054487  -97.563461\n",
      "44    UT  0.937060  40.150032 -111.862434\n",
      "45    VA  0.982750  37.769337  -78.169968\n",
      "46    VT       NaN  44.045876  -72.710686\n",
      "47    WA  0.794017  47.400902 -121.490494\n",
      "48    WI  0.922150  44.268543  -89.616508\n",
      "49    WV  1.249733  38.491226  -80.954454\n",
      "50    WY       NaN  42.755966 -107.302490\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"average_saar_per_state.csv\")\n",
    "\n",
    "# Add latitude and longitude columns based on the dictionary\n",
    "df['latitude'] = df['state'].map(lambda x: state_coords[x][0] if x in state_coords else None)\n",
    "df['longitude'] = df['state'].map(lambda x: state_coords[x][1] if x in state_coords else None)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(\"average_saar_per_state_with_coords.csv\", index=False)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
